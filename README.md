# Sign-Companion
Also added a Unpublish research paper, We are in middle of the process of publishing a research of this project.
If you dont wish to run program on your local computer , we have got some outputs/glimpse after running this program , you can watch it here.
:- https://drive.google.com/drive/u/1/folders/1KXTXMeBpuftTOJsSUpNWuvaPdzTiy5Ov


Our study focuses on the creation of a machine learning model for hand gesture identification that is specifically designed to aid and empower deaf and dumb people. We hope to overcome the communication gap by allowing these people to express themselves more effectively through hand gestures. Transferring knowledge from one location, person, or group to another is referred to as communication. The speaker, the message being delivered, and the listener make up this trio. Only when the audience understands the speaker's intended message can the attempt be deemed successful. The categories that it can be broken down into are as follows [1]: formal and informal communication, oral (face-to-face and across distance), written, non-verbal, feedback, visual, and active listening. 
            The channels that are predetermined. Unofficial or grapevine communication is the unstructured, unplanned exchange of information among members of a profession. either a structure or a protocol. The spoken exchange of words between people who are in close contact or who are separated by distance (using technology such as phone and video conversations, webinars, etc.) is known as oral communication (face-to-face and distance). Letters, emails, notices, and other written correspondence are all examples of written communication. Body language, gestures, and other nonverbal cues are all examples of nonverbal communication.
          When a person provides feedback on a good or service that is offered by a person, a business, or both, this is known as feedback communication. When a person receives information from a visual source—like television, social media, or any other source—the visual communication takes place. Active listening is the process of paying attention to and comprehending what the other person is saying in order to improve the effectiveness and meaning of the communication [1].  According to the most recent WHO (World Health Organisation) census, around 15% of the world's population is exceptionally able, with at least 5 to 7% of them being deaf and dumb. The primary issue that these deaf and dump people experience is that it is extremely difficult for them to communicate with one another and with the people around them in society. 
           Deaf and dumb persons can communicate with each other and with others by using nonverbal cues. A person who is deaf has a hearing impairment that prevents them from hearing, whereas a person who is dumb has a speech impairment that prevents them from speaking. It is challenging to create communication when one cannot speak or listen. Here sign languages play a crucial role in allowing people to communicate without using words. However, there is still a difficulty because not many people are familiar with sign language. Deaf and dumb persons may be able to communicate amongst themselves using sign languages, but it is difficult for them to communicate with those who have normal hearing and vice versa due to a lack of sign language understanding. 
          This problem can be handled by implementing a technological solution. Using such a system, one may quickly convert sign language movements into the generally spoken language, English. We solved the problem in a unique way. We established our own hand gesture data set apart from ASL because normal people are not taught hand signs and because we do not communicate in sign language on a daily basis, normal people may easily forget the sign language.So, because the gestures are representing general sentences shared in a specific business place just to get the work done easily for deaf and mute population, the number of gestures will be less (around 25-30 gestures). 
